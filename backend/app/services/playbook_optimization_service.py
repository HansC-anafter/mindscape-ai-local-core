"""
Playbook Optimization Service
Uses LLM to analyze usage patterns and generate optimization suggestions
"""

import os
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

from backend.app.models.personalized_playbook import OptimizationSuggestion, UsageAnalysis
from backend.app.services.playbook_store import PlaybookStore
from backend.app.services.mindscape_store import MindscapeStore
from backend.app.services.agent_runner import LLMProviderManager

logger = logging.getLogger(__name__)


class PlaybookOptimizationService:
    """Service for analyzing Playbook usage and generating optimization suggestions"""

    def __init__(self):
        self.playbook_store = PlaybookStore()
        self.mindscape_store = MindscapeStore()

    async def analyze_usage(
        self,
        profile_id: str,
        playbook_code: str
    ) -> UsageAnalysis:
        """
        Analyze Playbook usage patterns for a user

        Returns usage statistics and patterns
        """
        # Get user meta for usage stats
        user_meta = self.playbook_store.get_user_meta(profile_id, playbook_code)

        # Get execution history from events
        events = self.mindscape_store.list_events(
            profile_id=profile_id,
            limit=100
        )

        # Filter playbook-related events
        playbook_events = [
            e for e in events
            if e.channel == "playbook" and
            (isinstance(e.payload, dict) and e.payload.get("playbook_code") == playbook_code)
        ]

        # Calculate statistics
        total_executions = len(playbook_events)
        successful_executions = sum(
            1 for e in playbook_events
            if isinstance(e.payload, dict) and e.payload.get("status") == "completed"
        )
        failed_executions = total_executions - successful_executions

        # Extract durations
        durations = []
        for e in playbook_events:
            if isinstance(e.payload, dict) and e.payload.get("duration_seconds"):
                durations.append(e.payload["duration_seconds"])

        avg_duration = sum(durations) / len(durations) if durations else None

        # Analyze patterns (simplified - can be enhanced)
        most_skipped_steps = []  # TODO: Extract from execution metadata
        common_failure_reasons = []  # TODO: Extract from failed executions
        execution_times = []  # TODO: Extract time of day patterns

        return UsageAnalysis(
            playbook_code=playbook_code,
            profile_id=profile_id,
            total_executions=total_executions,
            successful_executions=successful_executions,
            failed_executions=failed_executions,
            average_duration_seconds=avg_duration,
            most_skipped_steps=most_skipped_steps,
            common_failure_reasons=common_failure_reasons,
            execution_times=execution_times,
            suggestions=[]  # Will be generated by LLM
        )

    async def generate_suggestions(
        self,
        profile_id: str,
        playbook_code: str,
        usage_analysis: Optional[UsageAnalysis] = None
    ) -> List[OptimizationSuggestion]:
        """
        Generate optimization suggestions using LLM

        Args:
            profile_id: User profile ID
            playbook_code: Playbook code to optimize
            usage_analysis: Optional pre-computed usage analysis

        Returns:
            List of optimization suggestions
        """
        # Get usage analysis if not provided
        if usage_analysis is None:
            usage_analysis = await self.analyze_usage(profile_id, playbook_code)

        # Get base Playbook
        from backend.app.services.playbook_loader import PlaybookLoader
        loader = PlaybookLoader()
        playbook = loader.get_playbook_by_code(playbook_code)

        if not playbook:
            logger.warning(f"Playbook not found: {playbook_code}")
            return []

        # Get user profile for context
        profile = self.mindscape_store.get_profile(profile_id)

        # Build prompt for LLM
        prompt = self._build_optimization_prompt(playbook, usage_analysis, profile)

        # Call LLM
        try:
            # Get LLM provider with profile-specific keys
            from backend.app.services.config_store import ConfigStore
            config_store = ConfigStore()
            config = config_store.get_or_create_config(profile_id)

            openai_key = config.agent_backend.openai_api_key or os.getenv("OPENAI_API_KEY")
            anthropic_key = config.agent_backend.anthropic_api_key or os.getenv("ANTHROPIC_API_KEY")

            llm_manager = LLMProviderManager(openai_key=openai_key, anthropic_key=anthropic_key)
            provider = llm_manager.get_provider()

            if not provider:
                logger.warning("No LLM provider available")
                return []

            response = await provider.generate_text(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.7
            )

            # Parse LLM response into suggestions
            suggestions = self._parse_suggestions(response)
            return suggestions

        except Exception as e:
            logger.error(f"Failed to generate suggestions: {e}")
            return []

    def _build_optimization_prompt(
        self,
        playbook,
        usage_analysis: UsageAnalysis,
        profile
    ) -> str:
        """Build prompt for LLM optimization"""

        prompt_parts = [
            "You are a Playbook optimization assistant. Analyze the following Playbook usage data and provide optimization suggestions.",
            "",
            f"Playbook: {playbook.metadata.name} ({playbook.metadata.playbook_code})",
            f"Description: {playbook.metadata.description}",
            "",
            "SOP Content:",
            playbook.sop_content[:1000],  # Limit length
            "",
            "Usage Statistics:",
            f"- Total executions: {usage_analysis.total_executions}",
            f"- Successful: {usage_analysis.successful_executions}",
            f"- Failed: {usage_analysis.failed_executions}",
            f"- Average duration: {usage_analysis.average_duration_seconds:.1f}s" if usage_analysis.average_duration_seconds else "- Average duration: N/A",
            "",
            "User Context:",
        ]

        if profile and profile.self_description:
            desc = profile.self_description
            prompt_parts.extend([
                f"- Identity: {desc.get('identity', 'N/A')}",
                f"- Current Goal: {desc.get('solving', 'N/A')}",
                f"- Challenges: {desc.get('thinking', 'N/A')}",
            ])

        prompt_parts.extend([
            "",
            "Please provide optimization suggestions in the following JSON format:",
            '{"suggestions": [',
            '  {',
            '    "suggestion_type": "skip_step|add_checklist|modify_sop|adjust_params",',
            '    "title": "Suggestion title",',
            '    "description": "Detailed description",',
            '    "rationale": "Why this suggestion is made",',
            '    "step_number": 2,  // For skip_step',
            '    "checklist_item": "Check item",  // For add_checklist',
            '    "sop_modification": "Modified SOP section",  // For modify_sop',
            '    "param_overrides": {}  // For adjust_params',
            '  }',
            ']}',
            "",
            "Focus on:",
            "1. Steps that can be skipped based on user patterns",
            "2. Checklist items that would help the user",
            "3. SOP modifications for better personalization",
            "4. Parameter adjustments for efficiency",
        ])

        return "\n".join(prompt_parts)

    def _parse_suggestions(self, llm_response: str) -> List[OptimizationSuggestion]:
        """Parse LLM response into OptimizationSuggestion objects"""
        import json
        import re

        suggestions = []

        try:
            # Try to extract JSON from response
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                for sug_data in data.get("suggestions", []):
                    try:
                        suggestion = OptimizationSuggestion(
                            suggestion_type=sug_data.get("suggestion_type", "modify_sop"),
                            title=sug_data.get("title", "Optimization Suggestion"),
                            description=sug_data.get("description", ""),
                            rationale=sug_data.get("rationale", ""),
                            step_number=sug_data.get("step_number"),
                            checklist_item=sug_data.get("checklist_item"),
                            sop_modification=sug_data.get("sop_modification"),
                            param_overrides=sug_data.get("param_overrides")
                        )
                        suggestions.append(suggestion)
                    except Exception as e:
                        logger.warning(f"Failed to parse suggestion: {e}")
        except Exception as e:
            logger.warning(f"Failed to parse LLM response: {e}")
            # Fallback: create a generic suggestion
            suggestions.append(OptimizationSuggestion(
                suggestion_type="modify_sop",
                title="Review Playbook Usage",
                description="Consider reviewing your Playbook usage patterns to identify optimization opportunities.",
                rationale="Based on your usage statistics, there may be opportunities to streamline the process."
            ))

        return suggestions

    async def create_variant_from_suggestions(
        self,
        profile_id: str,
        playbook_code: str,
        variant_name: str,
        selected_suggestions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Create a personalized variant based on selected suggestions

        Args:
            profile_id: User profile ID
            playbook_code: Base Playbook code
            variant_name: Name for the variant
            selected_suggestions: List of suggestion dictionaries to apply

        Returns:
            Created variant data
        """
        # Get base Playbook
        from backend.app.services.playbook_loader import PlaybookLoader
        loader = PlaybookLoader()
        playbook = loader.get_playbook_by_code(playbook_code)

        if not playbook:
            raise ValueError(f"Playbook not found: {playbook_code}")

        # Apply suggestions
        skip_steps = []
        custom_checklist = []
        execution_params = {}
        personalized_sop = None

        for suggestion in selected_suggestions:
            sug_type = suggestion.get("suggestion_type")

            if sug_type == "skip_step" and suggestion.get("step_number"):
                skip_steps.append(suggestion["step_number"])
            elif sug_type == "add_checklist" and suggestion.get("checklist_item"):
                custom_checklist.append(suggestion["checklist_item"])
            elif sug_type == "adjust_params" and suggestion.get("param_overrides"):
                execution_params.update(suggestion["param_overrides"])
            elif sug_type == "modify_sop" and suggestion.get("sop_modification"):
                # For now, store the modification suggestion
                # In future, could use LLM to merge modifications
                personalized_sop = suggestion.get("sop_modification")

        # Create variant
        variant_data = {
            "profile_id": profile_id,
            "base_playbook_code": playbook_code,
            "base_version": playbook.metadata.version,
            "variant_name": variant_name,
            "variant_description": f"Personalized variant based on usage optimization",
            "personalized_sop_content": personalized_sop,
            "skip_steps": skip_steps,
            "custom_checklist": custom_checklist,
            "execution_params": execution_params,
            "is_active": True,
            "is_default": False
        }

        return self.playbook_store.create_personalized_variant(variant_data)
