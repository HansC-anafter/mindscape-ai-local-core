"""
i18n Exporter
Tool to export i18n files for new locales using LLM translation
"""

import logging
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
from backend.appshared.llm_utils import build_prompt, call_llm
from backend.app.services.agent_runner import LLMProviderManager
import os

logger = logging.getLogger(__name__)


async def export_i18n_for_locale(
    namespace: str,
    source_locale: str,
    target_locale: str,
    output_path: Optional[Path] = None,
    llm_provider: Optional[Any] = None
) -> Path:
    """
    Export i18n file for target locale by translating from source locale

    This tool helps local teams bootstrap i18n files for new locales.
    It uses LLM to translate all keys from source locale to target locale,
    generating a draft YAML file that can be manually refined.

    Args:
        namespace: i18n namespace (e.g., "major_proposal")
        source_locale: Source locale to translate from (e.g., "zh-TW", "en")
        target_locale: Target locale to translate to (e.g., "ja-JP")
        output_path: Output file path (optional, defaults to i18n/playbooks/{namespace}.{target_locale}.yaml)
        llm_provider: LLM provider object (optional)

    Returns:
        Path to generated i18n file
    """
    try:
        # Load source i18n file
        backend_dir = Path(__file__).parent.parent
        source_file = backend_dir / "i18n" / "playbooks" / f"{namespace}.{source_locale}.yaml"

        if not source_file.exists():
            raise FileNotFoundError(f"Source i18n file not found: {source_file}")

        with open(source_file, 'r', encoding='utf-8') as f:
            source_data = yaml.safe_load(f) or {}

        # Determine output path
        if output_path is None:
            output_path = backend_dir / "i18n" / "playbooks" / f"{namespace}.{target_locale}.yaml"

        # Ensure output directory exists
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # Get LLM provider
        if not llm_provider:
            openai_key = os.getenv("OPENAI_API_KEY")
            anthropic_key = os.getenv("ANTHROPIC_API_KEY")
            llm_manager = LLMProviderManager(openai_key=openai_key, anthropic_key=anthropic_key)
            llm_provider = llm_manager.get_provider()
            if not llm_provider:
                raise ValueError("No LLM provider available. Please configure OpenAI or Anthropic API key.")

        # Translate all keys recursively
        translated_data = await _translate_i18n_data(
            data=source_data,
            source_locale=source_locale,
            target_locale=target_locale,
            namespace=namespace,
            llm_provider=llm_provider
        )

        # Add header comment
        output_content = f"""# {namespace.title()} Playbook - {target_locale}
# Auto-generated by i18n exporter from {source_locale}

"""

        # Write YAML
        yaml_content = yaml.dump(
            translated_data,
            default_flow_style=False,
            allow_unicode=True,
            sort_keys=False,
            width=120
        )
        output_content += yaml_content

        # Write to file
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(output_content)

        logger.info(f"Exported i18n file: {output_path} ({len(translated_data)} top-level keys)")
        return output_path

    except Exception as e:
        logger.error(f"Failed to export i18n file: {e}")
        raise


async def _translate_i18n_data(
    data: Dict[str, Any],
    source_locale: str,
    target_locale: str,
    namespace: str,
    llm_provider: Any,
    parent_key: str = ""
) -> Dict[str, Any]:
    """
    Recursively translate i18n data structure

    Args:
        data: Source i18n data (nested dict)
        source_locale: Source locale name
        target_locale: Target locale name
        namespace: i18n namespace (for context)
        llm_provider: LLM provider
        parent_key: Parent key path (for logging)

    Returns:
        Translated data structure
    """
    translated = {}

    for key, value in data.items():
        current_key = f"{parent_key}.{key}" if parent_key else key

        if isinstance(value, dict):
            # Recursively translate nested dict
            translated[key] = await _translate_i18n_data(
                data=value,
                source_locale=source_locale,
                target_locale=target_locale,
                namespace=namespace,
                llm_provider=llm_provider,
                parent_key=current_key
            )
        elif isinstance(value, str):
            # Translate string value
            if value.strip():  # Only translate non-empty strings
                translated_value = await _translate_string(
                    text=value,
                    source_locale=source_locale,
                    target_locale=target_locale,
                    context_key=current_key,
                    llm_provider=llm_provider
                )
                translated[key] = translated_value
            else:
                translated[key] = value
        else:
            # Keep non-string values as-is
            translated[key] = value

    return translated


async def _translate_string(
    text: str,
    source_locale: str,
    target_locale: str,
    context_key: str,
    llm_provider: Any
) -> str:
    """
    Translate a single string using LLM

    Args:
        text: Text to translate
        source_locale: Source locale
        target_locale: Target locale
        context_key: Context key (for better translation quality)
        llm_provider: LLM provider

    Returns:
        Translated text
    """
    # Build translation prompt
    system_prompt = f"""You are a professional translator specializing in software localization.

Translate the following text from {source_locale} to {target_locale}.

Context: This is a UI text or prompt for a playbook system (key: {context_key}).

Requirements:
1. Maintain the original meaning and tone
2. Keep technical terms consistent
3. Preserve placeholders like {{variable_name}}
4. Maintain formatting (line breaks, markdown if present)
5. Use natural, native-sounding language

Translate only the content, do not add explanations."""

    user_prompt = f"Translate the following text:\n\n{text}"

    messages = build_prompt(system_prompt=system_prompt, user_prompt=user_prompt)

    # Call LLM
    from backend.appshared.llm_utils import call_llm
    result = await call_llm(messages=messages, llm_provider=llm_provider)

    translated = result.get("text", text).strip()

    # Remove any markdown code blocks if LLM added them
    if translated.startswith("```"):
        lines = translated.split("\n")
        if len(lines) > 2 and lines[0].startswith("```"):
            translated = "\n".join(lines[1:-1])

    return translated







