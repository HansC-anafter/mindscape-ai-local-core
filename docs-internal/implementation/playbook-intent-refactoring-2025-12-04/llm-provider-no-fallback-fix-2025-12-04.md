# LLM Provider ç¦æ­¢ Fallback ä¿®å¾©

**æ—¥æœŸ**ï¼š2025-12-04
**è¦æ±‚**ï¼šç¦æ­¢ä»»ä½• fallback å’Œç„¡è…¦æŒ‘é¸ç¬¬ä¸€å€‹æ¨¡å‹çš„è¡Œç‚ºï¼Œæ‰€æœ‰æ¨¡å‹é¸ç”¨éƒ½å¿…é ˆç”¨æˆ¶æŒ‡å®š

---

## ğŸ¯ æ ¸å¿ƒåŸå‰‡

1. **ç¦æ­¢ fallback**ï¼šä¸å…è¨±è‡ªå‹•é¸æ“‡ç¬¬ä¸€å€‹å¯ç”¨çš„ provider
2. **å¿…é ˆç”¨æˆ¶æŒ‡å®š**ï¼šæ‰€æœ‰ LLM provider é¸æ“‡éƒ½å¿…é ˆåŸºæ–¼ç”¨æˆ¶é…ç½®çš„ `chat_model`
3. **æ˜ç¢ºå ±éŒ¯**ï¼šå¦‚æœç”¨æˆ¶æœªé…ç½®æˆ–æŒ‡å®šçš„ provider ä¸å¯ç”¨ï¼Œç›´æ¥å ±éŒ¯ï¼Œä¸ fallback

---

## âœ… å·²å®Œæˆçš„ä¿®å¾©

### 1. ä¿®æ”¹ `LLMProviderManager.get_provider()`

**æ–‡ä»¶**ï¼š`backend/app/services/agent_runner.py`

**ä¿®æ”¹å‰**ï¼š
```python
def get_provider(self, provider_name: Optional[str] = None) -> Optional[LLMProvider]:
    """Get LLM provider by name, or return first available"""
    if not self.providers:
        return None

    if provider_name and provider_name in self.providers:
        return self.providers[provider_name]

    # Return first available provider  âŒ ç¦æ­¢æ­¤è¡Œç‚º
    return list(self.providers.values())[0]
```

**ä¿®æ”¹å¾Œ**ï¼š
```python
def get_provider(self, provider_name: Optional[str] = None) -> Optional[LLMProvider]:
    """
    Get LLM provider by name

    Args:
        provider_name: Provider name (required, no fallback)

    Returns:
        LLMProvider instance or None if not found

    Raises:
        ValueError: If provider_name is not specified
    """
    if not provider_name:
        raise ValueError(
            "provider_name is required. Cannot use fallback to first available provider. "
            "Please specify the provider name explicitly."
        )

    if not self.providers:
        return None

    if provider_name in self.providers:
        return self.providers[provider_name]

    return None
```

### 2. å‰µå»ºçµ±ä¸€çš„ Helper å‡½æ•¸

**æ–‡ä»¶**ï¼š`backend/app/shared/llm_provider_helper.py`ï¼ˆæ–°å»ºï¼‰

**åŠŸèƒ½**ï¼š
- `get_provider_name_from_chat_model()`ï¼šå¾ç³»çµ±è¨­ç½®è®€å– `chat_model` ä¸¦æ¨æ–· provider_name
- `get_llm_provider_from_settings()`ï¼šç²å– LLM providerï¼ˆåŸºæ–¼ç”¨æˆ¶é…ç½®ï¼Œç„¡ fallbackï¼‰

**ç‰¹é»**ï¼š
- âœ… å¾ç³»çµ±è¨­ç½®è®€å– `chat_model`
- âœ… å¾æ¨¡å‹åç¨±æ¨æ–· providerï¼ˆopenai/anthropic/vertex-aiï¼‰
- âœ… å¦‚æœæœªé…ç½®æˆ–ä¸å¯ç”¨ï¼Œç›´æ¥å ±éŒ¯
- âœ… ç„¡ä»»ä½• fallback é‚è¼¯

### 3. æ›´æ–° `PlaybookRunner`

**æ–‡ä»¶**ï¼š`backend/app/services/playbook_runner.py`

**ä¿®æ”¹**ï¼š
- `_get_llm_provider()` ç¾åœ¨ä½¿ç”¨çµ±ä¸€çš„ helper å‡½æ•¸
- ç§»é™¤äº†æ‰€æœ‰ fallback é‚è¼¯
- å¦‚æœ `chat_model` æœªé…ç½®æˆ– provider ä¸å¯ç”¨ï¼Œç›´æ¥å ±éŒ¯

---

## âœ… å·²ä¿®å¾©çš„èª¿ç”¨é»

ä»¥ä¸‹æ–‡ä»¶ä¸­çš„ `get_provider()` èª¿ç”¨å·²å…¨éƒ¨ä¿®å¾©ï¼Œä½¿ç”¨ `get_llm_provider_from_settings()`ï¼š

### é«˜å„ªå…ˆç´šï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰

1. **`backend/app/services/agent_runner.py:1091`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(self.llm_manager)`

2. **`backend/app/services/conversation/execution_coordinator.py:571, 610`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_manager)`

3. **`backend/app/services/conversation/plan_builder.py:292, 295`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_manager)`ï¼Œç§»é™¤æ‰€æœ‰ fallback é‚è¼¯

4. **`backend/app/services/conversation/conversation_orchestrator.py:137, 591`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_manager)`

5. **`backend/app/services/conversation_orchestrator.py:135, 584`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_manager)`

### ä¸­å„ªå…ˆç´šï¼ˆè¼”åŠ©åŠŸèƒ½ï¼‰

6. **`backend/app/shared/llm_utils.py:130, 132`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_provider)`ï¼Œç§»é™¤ fallback é‚è¼¯

7. **`backend/app/services/conversation/context_builder.py:659`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_manager)`

8. **`backend/app/services/conversation/cta_handler.py:973`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_manager)`

### ä½å„ªå…ˆç´šï¼ˆå…¶ä»–åŠŸèƒ½ï¼‰

9. **`backend/features/mindscape/routes.py:524, 556, 834`** âœ…
   - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(agent_runner.llm_manager)`ï¼Œæ·»åŠ éŒ¯èª¤è™•ç†

10. **`backend/app/services/execution_fallback_service.py:77`** âœ…
    - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_provider)`

11. **`backend/app/services/playbook_optimization_service.py:133`** âœ…
    - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_manager)`ï¼Œæ·»åŠ éŒ¯èª¤è™•ç†

12. **`backend/app/services/backends/local_llm_backend.py:53`** âœ…
    - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(self.llm_manager)`

13. **`backend/app/shared/i18n_exporter.py:64`** âœ…
    - ä¿®å¾©ï¼šä½¿ç”¨ `get_llm_provider_from_settings(llm_manager)`
    - åŒæ™‚ä¿®å¾©å°å…¥éŒ¯èª¤ï¼š`backend.appshared.llm_utils` â†’ `backend.app.shared.llm_utils`

---

## ğŸ”§ ä¿®å¾©æ¨¡æ¿

### æ¨™æº–ä¿®å¾©æ–¹æ³•

**ä¿®å¾©å‰**ï¼š
```python
llm_manager = self._get_llm_manager(profile_id)
provider = llm_manager.get_provider()  # âŒ ç„¡ provider_name
```

**ä¿®å¾©å¾Œ**ï¼š
```python
from backend.app.shared.llm_provider_helper import get_llm_provider_from_settings

llm_manager = self._get_llm_manager(profile_id)
provider = get_llm_provider_from_settings(llm_manager)  # âœ… ä½¿ç”¨ç”¨æˆ¶é…ç½®
```

---

## ğŸ“‹ é©—è­‰æ¸…å–®

ä¿®å¾©å®Œæˆå¾Œï¼Œé©—è­‰ä»¥ä¸‹å…§å®¹ï¼š

- [x] æ‰€æœ‰ `get_provider()` èª¿ç”¨éƒ½æŒ‡å®šäº† `provider_name` æˆ–ä½¿ç”¨ `get_llm_provider_from_settings()`
- [x] æ²’æœ‰ `get_provider()` ç„¡åƒæ•¸èª¿ç”¨ï¼ˆå·²é€šé grep é©—è­‰ï¼‰
- [x] æ‰€æœ‰éŒ¯èª¤æ¶ˆæ¯æ˜ç¢ºæŒ‡å‡ºéœ€è¦é…ç½® `chat_model`
- [ ] æ¸¬è©¦æ‰€æœ‰åŠŸèƒ½ï¼Œç¢ºä¿åœ¨æœªé…ç½® `chat_model` æ™‚æ­£ç¢ºå ±éŒ¯
- [ ] æ¸¬è©¦æ‰€æœ‰åŠŸèƒ½ï¼Œç¢ºä¿åœ¨æŒ‡å®šçš„ provider ä¸å¯ç”¨æ™‚æ­£ç¢ºå ±éŒ¯

---

## ğŸ¯ é æœŸè¡Œç‚º

### å ´æ™¯ 1ï¼šç”¨æˆ¶æœªé…ç½® chat_model

**è¡Œç‚º**ï¼šç›´æ¥å ±éŒ¯
```
ValueError: chat_model not configured in system settings. Please configure chat_model in Settings.
```

### å ´æ™¯ 2ï¼šç”¨æˆ¶é…ç½®äº† chat_modelï¼Œä½†å°æ‡‰çš„ provider ä¸å¯ç”¨

**è¡Œç‚º**ï¼šç›´æ¥å ±éŒ¯
```
ValueError: Selected provider 'openai' (from chat_model 'gpt-4o-mini') is not available.
Available providers: anthropic, vertex-ai.
Please configure the API key for 'openai' in Settings.
```

### å ´æ™¯ 3ï¼šç”¨æˆ¶é…ç½®äº† chat_modelï¼Œprovider å¯ç”¨

**è¡Œç‚º**ï¼šæ­£å¸¸ä½¿ç”¨æŒ‡å®šçš„ provider
```
[INFO] Using LLM provider 'anthropic' (from chat_model 'claude-3-5-sonnet-20241022')
```

---

## ğŸ“š ç›¸é—œæ–‡ä»¶

- `backend/app/services/agent_runner.py` - LLMProviderManager å¯¦ç¾
- `backend/app/shared/llm_provider_helper.py` - çµ±ä¸€çš„ helper å‡½æ•¸ï¼ˆæ–°å»ºï¼‰
- `backend/app/services/playbook_runner.py` - å·²ä¿®å¾©
- `backend/app/services/suggestion_generator.py` - åƒè€ƒå¯¦ç¾ï¼ˆå·²æ­£ç¢ºå¯¦ç¾ï¼‰

---

**æœ€å¾Œæ›´æ–°**ï¼š2025-12-04
**ç¶­è­·è€…**ï¼šMindscape AI é–‹ç™¼åœ˜éšŠ
**ç‹€æ…‹**ï¼šâœ… æ‰€æœ‰ä¿®å¾©å®Œæˆ

## ğŸ“ ä¿®å¾©æ‘˜è¦

**ä¿®å¾©æ—¥æœŸ**ï¼š2025-12-04

**ä¿®å¾©ç¯„åœ**ï¼š
- ä¿®å¾©äº† 13 å€‹æ–‡ä»¶ä¸­çš„ 20 è™•ç„¡åƒæ•¸ `get_provider()` èª¿ç”¨
- æ‰€æœ‰èª¿ç”¨é»å·²æ”¹ç‚ºä½¿ç”¨ `get_llm_provider_from_settings()`
- ç§»é™¤äº†æ‰€æœ‰ fallback é‚è¼¯
- æ·»åŠ äº†é©ç•¶çš„éŒ¯èª¤è™•ç†

**ä¿®å¾©çš„æ–‡ä»¶åˆ—è¡¨**ï¼š
1. `backend/app/services/agent_runner.py` (1è™•)
2. `backend/app/services/conversation/execution_coordinator.py` (2è™•)
3. `backend/app/services/conversation/plan_builder.py` (2è™•ï¼Œç§»é™¤ fallback)
4. `backend/app/services/conversation/conversation_orchestrator.py` (2è™•)
5. `backend/app/services/conversation_orchestrator.py` (2è™•)
6. `backend/app/shared/llm_utils.py` (2è™•ï¼Œç§»é™¤ fallback)
7. `backend/app/services/conversation/context_builder.py` (1è™•)
8. `backend/app/services/conversation/cta_handler.py` (1è™•)
9. `backend/features/mindscape/routes.py` (3è™•)
10. `backend/app/services/execution_fallback_service.py` (1è™•)
11. `backend/app/services/playbook_optimization_service.py` (1è™•)
12. `backend/app/services/backends/local_llm_backend.py` (1è™•)
13. `backend/app/shared/i18n_exporter.py` (1è™•ï¼ŒåŒæ™‚ä¿®å¾©å°å…¥éŒ¯èª¤)

**é©—è­‰çµæœ**ï¼š
- âœ… ä½¿ç”¨ `grep` é©—è­‰ï¼šç„¡ä»»ä½•ç„¡åƒæ•¸ `get_provider()` èª¿ç”¨
- âœ… æ‰€æœ‰æ–‡ä»¶å·²æ·»åŠ å¿…è¦çš„å°å…¥èªå¥
- âœ… éŒ¯èª¤è™•ç†å·²é©ç•¶æ·»åŠ 

