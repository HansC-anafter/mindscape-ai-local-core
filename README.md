# Mindscape AI Local Core

> **Open-source, local-only version of Mindscape AI**

[ä¸­æ–‡](README.zh.md) | [English](README.md)

This repository (`mindscape-ai-local-core`) is a clean, local-first AI workspace that helps you organize thoughts, manage tasks, and execute workflows through an intelligent conversation interface.

## ğŸ§  What is the Mindscape Algorithm?

**å¿ƒæ™ºç©ºé–“ç®—æ³•ï¼ˆMindscape Algorithmï¼‰** æ˜¯ Mindscape AI çš„æ ¸å¿ƒæ¶æ§‹ç†å¿µã€‚

å®ƒæŠŠä½¿ç”¨è€…çš„é•·æœŸæ„åœ–ã€å°ˆæ¡ˆä¸»ç·šã€å‰µä½œä¸»é¡Œï¼Œæ•´ç†æˆä¸€å€‹**å¯æ²»ç†ã€å¯å°èˆªçš„å¿ƒæ™ºç©ºé–“**ï¼Œè®“ LLM ä¸å†åªæ˜¯å›ç­”å–®ä¸€å•é¡Œï¼Œè€Œæ˜¯åœç¹ä½ çš„æ•´é«”äººç”Ÿï¼å·¥ä½œä¸»ç·šä¸€èµ·æ€è€ƒèˆ‡è¡Œå‹•ã€‚

The **Mindscape Algorithm** is the core architectural idea behind Mindscape AI.

It organizes a user's long-term intentions, project storylines, and creative themes into a **governable, navigable cognitive space**, and uses this as the backbone for intent-aware LLM agents and workflows.

ğŸ“– Learn more: [The Mindscape Algorithm](./docs/mindscape-algorithm.md) | [Mindscape AI Website](https://mindscapeai.app)

## ğŸ¯ What is Mindscape AI Local Core?

The `mindscape-ai-local-core` repository is the **open-source foundation** of Mindscape AI. It provides:

- **Intent/Workflow Engine**: AI-powered intent extraction and playbook execution
- **Port/Adapter Architecture**: Clean separation between core and external integrations
- **Local-First Design**: All data stored locally, no cloud dependencies
- **Extensible**: Ready for cloud extensions through adapter pattern

## âœ¨ Key Features

- **Intent Extraction**: Automatically extract intents and themes from user messages
- **Playbook Execution**: Execute multi-step workflows (playbooks) based on intents
- **Project + Flow Architecture** (v2.0): Multi-playbook orchestration within project containers
- **Layered Memory System**: Workspace core, project, and member profile memories
- **Timeline View**: Visualize workspace activity and execution history
- **File Processing**: Analyze and extract content from uploaded files
- **Port Architecture**: Clean abstraction layer for future cloud extensions

## ğŸ’¡ Who is this for?

Mindscape AI is built for people who:

- Often juggle multiple side projects, ideas, and long-term goals, but struggle to see which threads they're actually pushing forward
- Want more than "ask AI a question, get an answer"â€”they want AI to truly understand what they're working on and who they're becoming
- Prefer incremental change: one step at a time, with more awareness and conscious choices, rather than seeking one big transformation

If this sounds like you, Mindscape AI Local Core gives you a local-first, open-source playground to experiment with your own "mindscape".

## ğŸ—ï¸ Architecture

### Mindscape Architecture (3 Layers)

Mindscape AI ä¸æ˜¯åªåšä¸€å€‹èŠå¤©æ¡†ï¼Œè€Œæ˜¯åœç¹ã€Œæ„åœ–ã€è¨­è¨ˆäº†ä¸‰å±¤çµæ§‹ï¼š

1. **Signal Layer â€” æ”¶é›†ä¸€åˆ‡ç·šç´¢**

   å°è©±ã€æ–‡ä»¶ã€å·¥å…·å›å‚³ã€Playbook åŸ·è¡Œçµæœï¼Œéƒ½æœƒè¢«è½‰æˆè¼•é‡çš„ **IntentSignal**ï¼Œä½œç‚ºç³»çµ±ç†è§£ä½ åœ¨ã€Œå¿™äº›ä»€éº¼ã€çš„åº•å±¤è¨Šè™Ÿã€‚

2. **Intent Governance Layer â€” å¹«ä½ æ•´ç†ä¸»ç·š**

   Signal æœƒè¢«æ”¶æ–‚æˆ **IntentCard**ï¼ˆé•·æœŸæ„åœ–ï¼‰èˆ‡ **çŸ­æœŸä»»å‹™**ï¼Œä¸¦èšæˆ **IntentCluster**ï¼ˆå°ˆæ¡ˆï¼ä¸»é¡Œï¼‰ã€‚é€™ä¸€å±¤å°±æ˜¯æ‰€è¬‚çš„ã€Œå¿ƒæ™ºç©ºé–“ã€ï¼Œè² è²¬ç¶­è­·ä½ çš„å·¥ä½œèˆ‡ç”Ÿæ´»ä¸»ç·šã€‚

3. **Execution & Semantic Layer â€” çœŸçš„å»å¹¹æ´»**

   ç•¶æŸæ¢ Intent æº–å‚™å¥½ï¼Œå°±äº¤çµ¦ Playbookã€å·¥å…·ã€ä»¥åŠå„ç¨®èªæ„å¼•æ“å»åŸ·è¡Œï¼ŒåŒ…å« RAG æŸ¥è©¢ã€æ–‡ä»¶ç”Ÿæˆã€è·¨å·¥å…·è‡ªå‹•åŒ–å·¥ä½œæµç­‰ã€‚

### Technical Architecture

Mindscape AI Local Core uses a **Port/Adapter pattern** (Hexagonal Architecture) to maintain clean boundaries:

- **Core Domain**: ExecutionContext, Port interfaces, core services
- **Local Adapters**: Single-user, single-workspace implementations
- **No Cloud Dependencies**: Core is completely independent of cloud/tenant concepts

In addition, `mindscape-ai-local-core` introduces a Playbook-based workflow layer:

- A **Workspace LLM** for human-facing conversations
- A **Playbook LLM + workflow runtime** for executing multi-step workflows (`playbook.run = playbook.md + playbook.json`)

### Project + Flow + Sandbox Architecture (v2.0)

Starting from v2.0, Mindscape AI introduces a **Project-based collaboration model**:

- **Workspace**: Long-term collaboration room for teams/clients
- **Project**: Deliverable-level container with its own lifecycle (open, closed, archived)
- **Playbook Flow**: Multi-playbook orchestration with dependency resolution
- **Project Sandbox**: Unified file space shared across all playbooks in a project
- **Layered Memory**: Workspace core, project, and member profile memories

**Key Innovation**: Projects emerge naturally from conversations. When a conversation indicates a project need, the system automatically suggests creating a Project, allowing multiple playbooks to collaborate on the same deliverable.

See [Architecture Documentation](./docs/architecture/) and [Core Architecture Docs](./docs/core-architecture/) for details.

## ğŸš€ Quick Start

### Option 1: Docker Deployment (Recommended)

The easiest way to get started is using Docker:

```bash
# Clone the repository
git clone https://github.com/HansC-anafter/mindscape-ai-local-core.git
cd mindscape-ai-local-core

# (Optional) Create .env file with your API keys
# You can also configure API keys through the web interface after starting services
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY or ANTHROPIC_API_KEY

# Start all services
docker compose up -d

# View logs
docker compose logs -f
```

Access the application:
- **Frontend**: http://localhost:3001 (Docker deployment, production-like)
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

See [Docker Deployment Guide](./docs/getting-started/docker.md) for detailed instructions.

### Option 2: Manual Installation

#### Prerequisites

- Python 3.9+
- Node.js 18+ (for frontend)
- SQLite (included with Python)

#### Installation

```bash
# Clone the repository
git clone https://github.com/HansC-anafter/mindscape-ai-local-core.git
cd mindscape-ai-local-core

# Install backend dependencies
cd backend
pip install -r requirements.txt

# Install frontend dependencies
cd ../web-console
npm install
```

#### Running

```bash
# Start backend (from backend directory)
uvicorn app.main:app --reload

# Start frontend (from web-console directory, in a new terminal)
cd web-console
npm run dev
```

Visit `http://localhost:3000` to access the web interface (local dev server, frontend `npm run dev`).

For a more detailed setup guide, see [QUICKSTART.md](./QUICKSTART.md) or [Installation Guide](./docs/getting-started/installation.md).

## ğŸ“š Documentation

### Getting Started
- [Getting Started](./docs/getting-started/quick-start.md) - Installation and setup guide
- [Docker Deployment](./docs/getting-started/docker.md) - Deploy using Docker Compose
- [Installation Guide](./docs/getting-started/installation.md) - Manual installation instructions

### Core Concepts
- [The Mindscape Algorithm](./docs/mindscape-algorithm.md) - Core philosophy and 3-layer architecture
- [Mindscape AI Website](https://mindscapeai.app) - Complete technical whitepaper and product introduction (coming soon)

### Architecture Documentation
- [Architecture Documentation](./docs/core-architecture/README.md) - Complete system architecture, including:
  - Port/Adapter Architecture
  - Memory & Intent Architecture
  - Execution Context
  - Local/Cloud Boundary
  - Playbooks & Workflows
  - Project + Flow + Sandbox (v2.0)

## ğŸ§© Port Architecture

The local core (`mindscape-ai-local-core`) uses Port interfaces to enable clean separation:

- **IdentityPort**: Get execution context (local adapter returns single-user context)
- **IntentRegistryPort**: Resolve user input to intents (local adapter uses LLM)
- **PlaybookExecutorPort**: Execute Playbook runs (`playbook.run = md + json`) against a local or remote workflow runtime (âœ… implemented)

**Future Plans**:
- Custom contextual UI panels for playbook execution

Future cloud extensions can implement these ports without modifying core code.

See [Port Architecture](./docs/architecture/port-architecture.md) for details.

## ğŸ”¬ For Developers / Researchers

Mindscape AI æŠŠè‡ªå·±å®šä½åœ¨ã€Œ**intent-first çš„ LLM agent æ¶æ§‹**ã€ï¼š

* å— Conceptual Spaces & Cognitive Maps å•Ÿç™¼ï¼Œæˆ‘å€‘æŠŠ IntentCard / IntentCluster è¦–ç‚ºä¸€å¼µå¯å°èˆªçš„ **æ„åœ–åœ°åœ–**ã€‚
* å— BDI èˆ‡éšå±¤å¼å¼·åŒ–å­¸ç¿’ï¼ˆoptionsï¼‰å•Ÿç™¼ï¼Œæˆ‘å€‘æŠŠ Intent Layer è¦–ç‚ºé«˜éšæ±ºç­–å±¤ï¼ŒPlaybook èˆ‡åŸ·è¡Œå¼•æ“å‰‡å°ˆå¿ƒåšåŸ·è¡Œã€‚
* å— Active Inference å•Ÿç™¼ï¼Œæˆ‘å€‘æŠŠä½¿ç”¨è€…çš„åå¥½èˆ‡é•·æœŸç›®æ¨™ï¼Œæ”¶æ–‚æˆä¸€çµ„èƒ½å¼•å°ã€Œä¸‹ä¸€æ­¥æœ€å€¼å¾—åšä»€éº¼ã€çš„åå¥½åˆ†ä½ˆã€‚

å¦‚æœä½ å°é€™äº›ä¸»é¡Œæœ‰èˆˆè¶£ï¼Œå¯ä»¥åƒè€ƒ [Mindscape AI Website](https://mindscapeai.app) äº†è§£å®Œæ•´è¨­è¨ˆèˆ‡æŠ€è¡“ç™½çš®æ›¸ï¼ˆå³å°‡æ¨å‡ºï¼‰ã€‚

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

## ğŸ“§ Contact & Community

Maintainer: [Hans Huang](https://github.com/HansC-anafter)

- ğŸ **Bug report or feature request**
  â†’ Please open a [GitHub Issue](/issues).

- ğŸ’¬ **Questions / ideas / sharing your use cases**
  â†’ Use [GitHub Discussions](/discussions) (recommended).

- ğŸ¤ **Collaboration & commercial use** (agencies, teams, hardware partners, etc.)
  â†’ Contact: `dev@mindscapeai.app`

> Please avoid sending support requests to personal emails or social media.

> Using Issues/Discussions helps the whole community benefit from the answers.

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](./LICENSE) for details.

## ğŸ”— Related Projects

- **Mindscape AI Cloud** (private): Multi-tenant cloud version built on top of this core
- **Mindscape WordPress Plugin**: WordPress integration for Mindscape AI

## ğŸ“ Status

This is the **open-source, local-only version** of Mindscape AI. Cloud / multi-tenant features are provided through separate repositories and are not included in this version.

---

**Built with â¤ï¸ by the Mindscape AI team**
